{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RgNssVTy8GO"
   },
   "source": [
    "# Proyecto 2 – Modelos de clasificación supervisada para evaluar la calidad de un automovil.\n",
    "\n",
    "**Integrantes del grupo:**\n",
    "- Yenny A Gonzalez Melendez.\n",
    "- Mateo A Duque Moya.\n",
    "- Daniel Fuquene Linares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tBLcn_Hgxrdn",
    "outputId": "dd571ddc-4ad3-4368-d335-f00afd4ee7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ucimlrepo) (2.1.4)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ucimlrepo) (2023.11.17)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instala el paquete ucimlrepo usando pip\n",
    "!pip3 install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in ./Library/Python/3.9/lib/python/site-packages (from ucimlrepo) (2023.11.17)\n",
      "Requirement already satisfied: pandas>=1.0.0 in ./Library/Python/3.9/lib/python/site-packages (from ucimlrepo) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Library/Python/3.9/lib/python/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.15.0)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "03UnimZn3Kf-",
    "outputId": "bc998366-da3f-4e62-ab29-7c2863cccdf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'ID': 249, 'type': 'NATIVE', 'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'venue': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Usamos el importador de la base para no cargar descargar la información .\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# metadata\n",
    "print(car_evaluation.metadata)\n",
    "\n",
    "# variable information\n",
    "print(car_evaluation.variables)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbHw1nBB9hZm"
   },
   "source": [
    "**Descripción del problema tomando en cuenta  las fuentes:**\n",
    "\n",
    "La base de datos proporcionada tiene como finalidad ofrecer información valiosa para la evaluación de distintos vehículos, tomando en cuenta diversas características que influyen en la percepción de calidad por parte de los consumidores. A continuación, relacionaremos las variables relevantes junto con sus respectivas categorías, que serán fundamentales para el análisis y la evaluación posterior. Este proceso incluye la aplicación de técnicas analíticas, así como el entrenamiento de modelos de clasificación supervisada para determinar la calidad de los automóviles. Las variables a considerar son las siguientes:\n",
    "\n",
    "\n",
    "*   **Costo de compra:** muy alto, alto, medio o bajo.\n",
    "*   **Mantenimiento:** muy alto, alto, medio o bajo.\n",
    "*   **Mantenimiento:** muy alto, alto, medio o bajo.\n",
    "*   **Puertas:** 2, 3, 4, 5  he incluso más.\n",
    "*   **Personas:** 2, 4, he incluso más.\n",
    "*   **Maletero:** pequeño, medio, grande.\n",
    "*   **Seguridad:** baja, media, alta.\n",
    "\n",
    "Tomando en cuenta la información relacionada anteriormente, es necesario realizar una conversion total de la base a valores numericos par realizar correctamente el entrenamiento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VRKgpWvtJU-N",
    "outputId": "67e8f36d-7cc5-49ed-b57f-fdf1f77a4ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Número de variables': 6, 'Número de registros': 1728, 'Variables numéricas': [], 'Variables cualitativas': ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']}\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# Asigna X a df\n",
    "df = X\n",
    "\n",
    "# Obtener la información de las variables del dataset\n",
    "variables_info = car_evaluation.variables\n",
    "\n",
    "# Listas para almacenar los nombres de las variables numéricas y cualitativas\n",
    "numericas = []\n",
    "cualitativas = []\n",
    "\n",
    "# Recorrer la información de las variables y clasificarlas\n",
    "# Se itera sobre las filas del DataFrame variables_info\n",
    "for index, row in variables_info.iterrows():\n",
    "    # Se accede a los valores de las columnas usando el nombre de la columna\n",
    "    if row['type'] == 'numeric':\n",
    "        numericas.append(row['name'])\n",
    "    else:  # Si no es numérica, se considera cualitativa\n",
    "        cualitativas.append(row['name'])\n",
    "\n",
    "# Tomar las columnas numéricas a tipo numérico (int o float)\n",
    "for col in numericas:\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# Campos Resumen\n",
    "resumen = {\n",
    "    'Número de variables': df.shape[1],\n",
    "    'Número de registros': df.shape[0],\n",
    "    'Variables numéricas': numericas,\n",
    "    'Variables cualitativas': cualitativas,\n",
    "}\n",
    "\n",
    "# Imprimir.\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd5MS2PKLdoW"
   },
   "source": [
    "**Resumen De La información:**\n",
    "\n",
    "\n",
    "Después de llevar a cabo un análisis inicial de los datos, podemos concluir que contamos con un total de 6 variables clasificatorias y 1,728 registros. Estas variables abarcan una amplia gama de características que nos permiten identificar las preferencias generales en el estudio. Cabe destacar que todas las variables son de la naturaleza clasificatoria que desarrollaremos a continuación.\n",
    "\n",
    "Es necesario adicionar la conversión que realizamos a las variables para su evaluación y entrenamiento como lo veremos a continuación en el print generado con la nueva tabla:\n",
    "\n",
    "*   **Costo de compra:** muy alto = 4, alto = 3, medio = 2  y  bajo = 1.\n",
    "*   **Mantenimiento:** muy alto = 4, alto = 3, medio = 2  y  bajo = 1.\n",
    "*   **Puertas:** 2, 3, 4, 5, 5 o más = 6.\n",
    "*   **Personas:** 2, 4, más = 5.\n",
    "*   **Maletero:** pequeño = 1, medio = 2, grande = 3.\n",
    "*   **Seguridad:** baja = 1, media = 2, alta = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "5_6qIIrvXUsY",
    "outputId": "8c1d1714-31f8-4eda-b3cd-7be3b2c0f185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'buying': ['vhigh' 'high' 'med' 'low']\n",
      "Valores únicos en 'maint': ['vhigh' 'high' 'med' 'low']\n",
      "Valores únicos en 'doors': ['2' '3' '4' '5more']\n",
      "Valores únicos en 'persons': ['2' '4' 'more']\n",
      "Valores únicos en 'lug_boot': ['small' 'med' 'big']\n",
      "Valores únicos en 'safety': ['low' 'med' 'high']\n",
      "      buying  maint  doors  persons  lug_boot  safety\n",
      "0          4      4      2        2         1       1\n",
      "1          4      4      2        2         1       2\n",
      "2          4      4      2        2         1       3\n",
      "3          4      4      2        2         2       1\n",
      "4          4      4      2        2         2       2\n",
      "...      ...    ...    ...      ...       ...     ...\n",
      "1723       1      1      6        5         2       2\n",
      "1724       1      1      6        5         2       3\n",
      "1725       1      1      6        5         3       1\n",
      "1726       1      1      6        5         3       2\n",
      "1727       1      1      6        5         3       3\n",
      "\n",
      "[1728 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/548952707.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].replace(mapping)\n"
     ]
    }
   ],
   "source": [
    "# Modificaciones realizadas (Diccionario)\n",
    "conversion_dict = {\n",
    "    'buying': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "    'maint': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "    'doors': {'2': 2, '3': 3, '4': 4, '5more': 6 },\n",
    "    'persons': {'2': 2, '4': 4, 'more': 5},\n",
    "    'lug_boot': {'small': 1, 'med': 2, 'big': 3},\n",
    "    'safety': {'low': 1, 'med': 2, 'high': 3}\n",
    "}\n",
    "\n",
    "\n",
    "# Valores únicos de cada columna\n",
    "for col in conversion_dict.keys():\n",
    "    if col in df.columns:\n",
    "        print(f\"Valores únicos en '{col}': {df[col].unique()}\")\n",
    "\n",
    "\n",
    "\n",
    "# uso de la función replace\n",
    "for col, mapping in conversion_dict.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace(mapping)\n",
    "\n",
    "# Pantallazo del DataFrame después de la conversión :)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "HeQI2ahifCuq",
    "outputId": "ea252b40-8750-416b-c446-c22a8483d627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'buying': [4 3 2 1]\n",
      "Valores únicos en 'maint': [4 3 2 1]\n",
      "Valores únicos en 'doors': [2 3 4 6]\n",
      "Valores únicos en 'persons': [2 4 5]\n",
      "Valores únicos en 'lug_boot': [1 2 3]\n",
      "Valores únicos en 'safety': [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos de cada columna\n",
    "for col in conversion_dict.keys():\n",
    "    if col in df.columns:\n",
    "        print(f\"Valores únicos en '{col}': {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO6Mzd4KcxTH"
   },
   "source": [
    "**División para entrenamiento:**\n",
    "\n",
    "A continuación relacionamos la division de la variable class para determinar el entrenamiento 80% y testeo del 20%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.11.4)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pIOW8ZEpbNzI",
    "outputId": "d76b4640-dc22-499a-a468-7e8637883057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del conjunto de entrenamiento (X_train): (1382, 6)\n",
      "Forma del conjunto de prueba (X_test): (346, 6)\n",
      "Forma del conjunto de entrenamiento (y_train): (1382, 1)\n",
      "Forma del conjunto de prueba (y_test): (346, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print de los conjuntos de entrenamiento y prueba\n",
    "print(\"Forma del conjunto de entrenamiento (X_train):\", X_train.shape)\n",
    "print(\"Forma del conjunto de prueba (X_test):\", X_test.shape)\n",
    "print(\"Forma del conjunto de entrenamiento (y_train):\", y_train.shape)\n",
    "print(\"Forma del conjunto de prueba (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeHS963zftZG"
   },
   "source": [
    "**Modelos De Aprendisaje Que Implementaremos:**\n",
    "\n",
    "\n",
    "*  Árbol de decisión, DecisionTreeClassifier\n",
    "*  Bosque aleatorio, RandomForestClassifier\n",
    "*  Regresión logística, LogisticRegression\n",
    "*  K-vecinos más cercanos, KNeighborsClassifier\n",
    "*  Máquina de vectores de soporte\", SVC\n",
    "*  Naive Bayes, GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Hr7EIdpIbmzn",
    "outputId": "0a01a917-c455-4cce-87f5-b3b243a2d0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para Árbol de decisión:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.97      0.92      0.94        83\n",
      "        good       0.56      0.91      0.69        11\n",
      "       unacc       1.00      1.00      1.00       235\n",
      "       vgood       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.97       346\n",
      "   macro avg       0.88      0.91      0.88       346\n",
      "weighted avg       0.98      0.97      0.97       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reporte de clasificación para Bosque aleatorio:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.99      0.88      0.93        83\n",
      "        good       0.56      0.91      0.69        11\n",
      "       unacc       0.99      1.00      1.00       235\n",
      "       vgood       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.97       346\n",
      "   macro avg       0.87      0.93      0.89       346\n",
      "weighted avg       0.97      0.97      0.97       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reporte de clasificación para Regresión logística:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.26      0.13      0.18        83\n",
      "        good       0.00      0.00      0.00        11\n",
      "       unacc       0.72      0.92      0.81       235\n",
      "       vgood       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.25      0.26      0.25       346\n",
      "weighted avg       0.55      0.66      0.59       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reporte de clasificación para K-vecinos más cercanos:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.83      0.72      0.77        83\n",
      "        good       0.36      0.36      0.36        11\n",
      "       unacc       0.92      1.00      0.96       235\n",
      "       vgood       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.88       346\n",
      "   macro avg       0.75      0.62      0.66       346\n",
      "weighted avg       0.88      0.88      0.88       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reporte de clasificación para Máquina de vectores de soporte:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.88      0.76      0.81        83\n",
      "        good       1.00      0.45      0.62        11\n",
      "       unacc       0.92      0.99      0.95       235\n",
      "       vgood       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.91       346\n",
      "   macro avg       0.93      0.77      0.83       346\n",
      "weighted avg       0.91      0.91      0.91       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Reporte de clasificación para Naive Bayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.50      0.10      0.16        83\n",
      "        good       0.00      0.00      0.00        11\n",
      "       unacc       0.82      0.81      0.82       235\n",
      "       vgood       0.17      1.00      0.30        17\n",
      "\n",
      "    accuracy                           0.62       346\n",
      "   macro avg       0.37      0.48      0.32       346\n",
      "weighted avg       0.69      0.62      0.61       346\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/var/folders/13/1yqm_l0d1y1823t4h71nr_2m0000gn/T/ipykernel_47298/138785377.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mateoduque/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Dataset\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets\n",
    "\n",
    "# Obtener la información de las variables del dataset\n",
    "variables_info = car_evaluation.variables\n",
    "\n",
    "# Listas para almacenar los nombres de las variables numéricas y cualitativas\n",
    "numericas = []\n",
    "cualitativas = []\n",
    "\n",
    "# Recorrer la información de las variables y clasificarlas\n",
    "for index, row in variables_info.iterrows():\n",
    "    if row['type'] == 'numeric':\n",
    "        numericas.append(row['name'])\n",
    "    else:\n",
    "        cualitativas.append(row['name'])\n",
    "\n",
    "# Excluir la columna 'class' de la lista cualitativas\n",
    "cualitativas = [col for col in cualitativas if col != 'class']\n",
    "\n",
    "# Convertir variables cualitativas a numéricas usando Label Encoding\n",
    "for col in cualitativas:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lista de modelos para evaluar\n",
    "modelos = [\n",
    "    (\"Árbol de decisión\", DecisionTreeClassifier()),\n",
    "    (\"Bosque aleatorio\", RandomForestClassifier()),\n",
    "    (\"Regresión logística\", LogisticRegression(max_iter=1000)),\n",
    "    (\"K-vecinos más cercanos\", KNeighborsClassifier()),\n",
    "    (\"Máquina de vectores de soporte\", SVC()),\n",
    "    (\"Naive Bayes\", GaussianNB())\n",
    "]\n",
    "\n",
    "# Iterar sobre los modelos y generar los reportes de clasificación\n",
    "for nombre_modelo, modelo in modelos:\n",
    "  # Entrenar el modelo\n",
    "  modelo.fit(X_train, y_train.values.ravel()) # Ajustar para usar .values.ravel()\n",
    "\n",
    "  # Realizar predicciones en el conjunto de prueba\n",
    "  y_pred = modelo.predict(X_test)\n",
    "\n",
    "  # Generar el reporte de clasificación\n",
    "  print(f\"Reporte de clasificación para {nombre_modelo}:\\n\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5smCPjmv1no"
   },
   "source": [
    "**Resumen de los modelos aplicados**\n",
    "\n",
    "**Árbol de Decisión y Bosque Aleatorio:**\n",
    "\n",
    "Buen desempeño general: Ambos modelos muestran un buen desempeño, especialmente en la clase \"unacc\".\n",
    "F1-score alto: El F1-score es alto para ambas clases, lo que indica un buen equilibrio entre precisión y recall.\n",
    "Bosque Aleatorio ligeramente mejor: El Bosque Aleatorio parece tener un ligero borde sobre el Árbol de Decisión en términos de precisión y F1-score promedio. Esto es común, ya que los Bosques Aleatorios son un ensamblaje de múltiples árboles de decisión, lo que reduce el sobreajuste y mejora la precisión.\n",
    "\n",
    "**Regresión Logística:**\n",
    "\n",
    "Desempeño pobre: La Regresión Logística tiene un desempeño significativamente peor que los otros modelos, especialmente en las clases \"bueno\" y \"vgood\".\n",
    "Sesgo hacia la clase mayoritaria: El modelo parece estar sesgado hacia la clase mayoritaria (\"unacc\"), lo que podría deberse a un desbalance en los datos.\n",
    "\n",
    "**K-vecinos más cercanos y Máquina de Vectores de Soporte:**\n",
    "\n",
    "Desempeño mixto: Estos modelos tienen un desempeño variable dependiendo de la clase.\n",
    "Sensibilidad a los hiperparámetros: El desempeño de estos modelos puede ser muy sensible a la elección de los hiperparámetros (como el número de vecinos en KNN o el kernel en SVM).\n",
    "\n",
    "**Naive Bayes:**\n",
    "\n",
    "Peor desempeño: Naive Bayes tiene el peor desempeño general de todos los modelos.\n",
    "Asunción de independencia: El supuesto de independencia condicional de Naive Bayes puede no ser válido en muchos casos reales, lo que puede afectar su precisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "oot4jwzazl0i",
    "outputId": "707749d7-a679-43fc-84f5-688373296ba7"
   },
   "source": [
    "**PUNTO 11**\n",
    "\n",
    "Basándome en el F1-score promedio y la consistencia en el desempeño a través de las diferentes clases, el Bosque Aleatorio parece ser el mejor candidato. Su capacidad de crear múltiples árboles de decisión y combinar sus resultados lo hace más robusto y menos propenso al sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el Bosque Aleatorio es un buen punto de partida, pero hay margen para mejorar el rendimiento del modelo. Ajustando los hiperparámetros, abordando el desequilibrio de clases y explorando otras técnicas, es posible obtener resultados aún mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
